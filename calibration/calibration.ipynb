{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir -p failed for path /dfs/user/sttruong/.cache/matplotlib: [Errno 13] Permission denied: '/dfs/user/sttruong'\n",
      "Matplotlib created a temporary cache directory at /tmp/user/21130/matplotlib-2z_egxhn because there was an issue with the default path (/dfs/user/sttruong/.cache/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "2025-06-05 05:39:37.471614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749127177.485482 2356811 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749127177.489712 2356811 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749127177.502208 2356811 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749127177.502221 2356811 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749127177.502223 2356811 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749127177.502224 2356811 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-05 05:39:37.506195: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.optim import LBFGS\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "import multiprocessing as mp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tueplots import bundles\n",
    "bundles.icml2024()\n",
    "\n",
    "from torchmetrics import AUROC\n",
    "auroc = AUROC(task=\"binary\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "def visualize_response_matrix(results, value, filename):\n",
    "    # Extract the groups labels in the order of the columns\n",
    "    group_values = results.columns.get_level_values(\"scenario\")\n",
    "\n",
    "    # Identify the boundaries where the group changes\n",
    "    boundaries = []\n",
    "    for i in range(1, len(group_values)):\n",
    "        if group_values[i] != group_values[i - 1]:\n",
    "            boundaries.append(i - 0.5)  # using 0.5 to place the line between columns\n",
    "\n",
    "    # Visualize the results with a matrix: red is 0, white is -1 and blue is 1\n",
    "    cmap = mcolors.ListedColormap([\"white\", \"red\", \"blue\"])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    # Calculate midpoints for each group label\n",
    "    groups_list = list(group_values)\n",
    "    group_names = []\n",
    "    group_midpoints = []\n",
    "    current_group = groups_list[0]\n",
    "    start_index = 0\n",
    "    for i, grp in enumerate(groups_list):\n",
    "        if grp != current_group:\n",
    "            midpoint = (start_index + i - 1) / 2.0\n",
    "            group_names.append(current_group)\n",
    "            group_midpoints.append(midpoint)\n",
    "            current_group = grp\n",
    "            start_index = i\n",
    "    # Add the last group\n",
    "    midpoint = (start_index + len(groups_list) - 1) / 2.0\n",
    "    group_names.append(current_group)\n",
    "    group_midpoints.append(midpoint)\n",
    "\n",
    "    # Define the minimum spacing between labels (e.g., 100 units)\n",
    "    min_spacing = 100\n",
    "    last_label_pos = -float(\"inf\")\n",
    "    # Plot the matrix\n",
    "    with plt.rc_context(bundles.icml2024(usetex=True, family=\"serif\")):\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        cax = ax.matshow(value, aspect=\"auto\", cmap=cmap, norm=norm)\n",
    "\n",
    "        # Add vertical lines at each boundary\n",
    "        for b in boundaries:\n",
    "            ax.axvline(x=b, color=\"black\", linewidth=0.25, linestyle=\"--\", alpha=0.5)\n",
    "        \n",
    "        # Add group labels above the matrix, only if they're spaced enough apart\n",
    "        for name, pos in zip(group_names, group_midpoints):\n",
    "            if pos - last_label_pos >= min_spacing:\n",
    "                ax.text(pos, -5, name, ha='center', va='bottom', rotation=90, fontsize=3)\n",
    "                last_label_pos = pos\n",
    "\n",
    "        # Add model labels on the y-axis\n",
    "        ax.set_yticks(range(len(results.index)))\n",
    "        ax.set_yticklabels(results.index, fontsize=3)\n",
    "\n",
    "        # Add a colorbar\n",
    "        cbar = plt.colorbar(cax)\n",
    "        cbar.set_ticks([-1, 0, 1])\n",
    "        cbar.set_ticklabels([\"-1\", \"0\", \"1\"])\n",
    "        plt.savefig(filename, dpi=600, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "def trainer(parameters, optim, closure, n_iter=100, verbose=True):\n",
    "    pbar = tqdm(range(n_iter)) if verbose else range(n_iter)\n",
    "    for iteration in pbar:\n",
    "        if iteration > 0:\n",
    "            previous_parameters = [p.clone() for p in parameters]\n",
    "            previous_loss = loss.clone()\n",
    "        \n",
    "        loss = optim.step(closure)\n",
    "        \n",
    "        if iteration > 0:\n",
    "            d_loss = (previous_loss - loss).item()\n",
    "            d_parameters = sum(\n",
    "                torch.norm(prev - curr, p=2).item()\n",
    "                for prev, curr in zip(previous_parameters, parameters)\n",
    "            )\n",
    "            grad_norm = sum(torch.norm(p.grad, p=2).item() for p in parameters if p.grad is not None)\n",
    "            if verbose:\n",
    "                pbar.set_postfix({\"grad_norm\": grad_norm, \"d_parameter\": d_parameters, \"d_loss\": d_loss})\n",
    "            \n",
    "            if d_loss < 1e-5 and d_parameters < 1e-5 and grad_norm < 1e-5:\n",
    "                break\n",
    "    return parameters\n",
    "\n",
    "def compute_auc(probs, data, train_idtor, test_idtor):\n",
    "    train_probs = probs[train_idtor.bool()]\n",
    "    test_probs = probs[test_idtor.bool()]\n",
    "    train_labels = data[train_idtor.bool()]\n",
    "    test_labels = data[test_idtor.bool()]\n",
    "    \n",
    "    train_auc = auroc(train_probs, train_labels)\n",
    "    test_auc = auroc(test_probs, test_labels)\n",
    "    print(f\"train auc: {train_auc}\")\n",
    "    print(f\"test auc: {test_auc}\")\n",
    "    \n",
    "    return train_auc, test_auc\n",
    "\n",
    "def compute_cttcorr(probs, data, train_idtor, test_idtor):\n",
    "    train_probs  = probs.clone()\n",
    "    test_probs   = probs.clone()\n",
    "    train_labels = data.clone()\n",
    "    test_labels  = data.clone()\n",
    "\n",
    "    train_mask = ~train_idtor.bool()\n",
    "    train_probs[train_mask]  = float('nan')\n",
    "    train_labels[train_mask] = float('nan')\n",
    "\n",
    "    test_mask = ~test_idtor.bool()\n",
    "    test_probs[test_mask]   = float('nan')\n",
    "    test_labels[test_mask]  = float('nan')\n",
    "    \n",
    "    train_prob_ctt = torch.nanmean(train_probs, dim=1).detach().cpu().numpy()\n",
    "    train_label_ctt = torch.nanmean(train_labels, dim=1).detach().cpu().numpy()\n",
    "    train_mask = ~np.isnan(train_prob_ctt) & ~np.isnan(train_label_ctt)\n",
    "    train_cttcorr = pearsonr(train_prob_ctt[train_mask], train_label_ctt[train_mask]).statistic\n",
    "    \n",
    "    test_prob_ctt = torch.nanmean(test_probs, dim=1).detach().cpu().numpy()\n",
    "    test_label_ctt = torch.nanmean(test_labels, dim=1).detach().cpu().numpy()\n",
    "    test_mask = ~np.isnan(test_prob_ctt) & ~np.isnan(test_label_ctt)\n",
    "    test_cttcorr = pearsonr(test_prob_ctt[test_mask], test_label_ctt[test_mask]).statistic\n",
    "    \n",
    "    print(f\"train cttcorr: {train_cttcorr}\")\n",
    "    print(f\"test cttcorr: {test_cttcorr}\")\n",
    "\n",
    "    return train_cttcorr, test_cttcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/resmat.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "    \n",
    "# data_withnan, missing=nan\n",
    "# data_withneg1, missing=-1\n",
    "# data_with0, missing=0\n",
    "data_withnan = torch.tensor(results.values, dtype=torch.float, device=device)\n",
    "data_withneg1 = data_withnan.nan_to_num(nan=-1.0)\n",
    "data_idtor = (data_withneg1 != -1).to(float)\n",
    "data_with0 = data_withneg1 * data_idtor # -1 -> 0\n",
    "n_test_takers, n_items = data_with0.shape\n",
    "scenarios = results.columns.get_level_values(\"scenario\").unique()\n",
    "\n",
    "# save dict\n",
    "metric_results = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test takers: 183\n",
      "Number of items: 78712\n",
      "Number of scenarios: 22\n",
      "air_bench_2024: 41 test takers, 4985 items\n",
      "babi_qa: 70 test takers, 3461 items\n",
      "bbq: 42 test takers, 999 items\n",
      "boolq: 67 test takers, 3316 items\n",
      "civil_comments: 67 test takers, 29407 items\n",
      "commonsense: 91 test takers, 498 items\n",
      "dyck_language_np=3: 69 test takers, 500 items\n",
      "entity_data_imputation: 67 test takers, 395 items\n",
      "entity_matching: 67 test takers, 1396 items\n",
      "gsm: 90 test takers, 997 items\n",
      "imdb: 67 test takers, 3530 items\n",
      "legal_support: 69 test takers, 594 items\n",
      "legalbench: 91 test takers, 1997 items\n",
      "lsat_qa: 69 test takers, 454 items\n",
      "math: 91 test takers, 436 items\n",
      "med_qa: 91 test takers, 998 items\n",
      "mmlu: 79 test takers, 13223 items\n",
      "raft: 67 test takers, 1336 items\n",
      "synthetic_reasoning: 69 test takers, 2234 items\n",
      "thai_exam: 40 test takers, 557 items\n",
      "truthful_qa: 67 test takers, 1888 items\n",
      "wikifact: 67 test takers, 5511 items\n"
     ]
    }
   ],
   "source": [
    "vis_resmat_dir = \"../result/visualize_resmat\"\n",
    "os.makedirs(vis_resmat_dir, exist_ok=True)\n",
    "\n",
    "# overall stats\n",
    "print(\"Number of test takers:\", results.shape[0])\n",
    "print(\"Number of items:\", results.shape[1])\n",
    "print(\"Number of scenarios:\", results.columns.get_level_values(\"scenario\").nunique())\n",
    "visualize_response_matrix(results, results, f\"{vis_resmat_dir}/resmat_all\")\n",
    "\n",
    "# count the number of items and test takers in each dataset\n",
    "scenario_counts = {}\n",
    "for scenario in sorted(scenarios):\n",
    "    mask = results.columns.get_level_values(\"scenario\") == scenario\n",
    "    sub_results = results.loc[:, mask]\n",
    "    scenario_counts[scenario] = {\n",
    "        \"n_items\": sub_results.shape[1],\n",
    "        \"n_test_takers\": sub_results.notna().any(axis=1).sum()\n",
    "    }\n",
    "    print(f\"{scenario}: {scenario_counts[scenario]['n_test_takers']} test takers, {scenario_counts[scenario]['n_items']} items\")\n",
    "    # visualize_response_matrix(sub_results, sub_results, f\"{vis_resmat_dir}/resmat_{scenario}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive auc 0: 0.5\n",
      "Naive auc 1.1: 0.8070003986358643\n",
      "Naive auc 1.2: 0.6573556065559387\n"
     ]
    }
   ],
   "source": [
    "# overall mean\n",
    "naive_prediction_0 = torch.nanmean(data_withnan)\n",
    "naive_prediction_0 = naive_prediction_0.expand(data_withnan.shape[0], data_withnan.shape[1])\n",
    "auc_train_0 = auroc(naive_prediction_0[data_idtor.bool()], data_withnan[data_idtor.bool()]).item()\n",
    "print(f\"Naive auc 0: {auc_train_0}\")\n",
    "\n",
    "# question difficulty average\n",
    "naive_prediction_1 = torch.nanmean(data_withnan, dim=0)\n",
    "naive_prediction_1 = naive_prediction_1[None, :].expand(data_withnan.shape[0], data_withnan.shape[1])\n",
    "auc_train_1_1 = auroc(naive_prediction_1[data_idtor.bool()], data_withnan[data_idtor.bool()]).item()\n",
    "print(f\"Naive auc 1.1: {auc_train_1_1}\")\n",
    "\n",
    "# test taker average\n",
    "naive_prediction_1 = torch.nanmean(data_withnan, dim=1)\n",
    "naive_prediction_1 = naive_prediction_1[:, None].expand(data_withnan.shape[0], data_withnan.shape[1])\n",
    "auc_train_1_2 = auroc(naive_prediction_1[data_idtor.bool()], data_withnan[data_idtor.bool()]).item()\n",
    "print(f\"Naive auc 1.2: {auc_train_1_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Rasch model\n",
    "\n",
    "fit one theat for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:16<08:49,  5.46s/it, grad_norm=1.01e-6, d_parameter=0, d_loss=0]\n",
      "  4%|▍         | 4/100 [00:03<01:33,  1.02it/s, grad_norm=4.07e-7, d_parameter=0, d_loss=0]\n",
      "100%|██████████| 2/2 [00:20<00:00, 10.15s/it]\n",
      "  7%|▋         | 7/100 [00:00<00:06, 13.52it/s, grad_norm=1.99e-7, d_parameter=0, d_loss=6.58e-11]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.8401544094085693\n",
      "test auc: 0.8265177607536316\n",
      "train cttcorr: 0.9999982965698357\n",
      "test cttcorr: 0.9927450093359975\n"
     ]
    }
   ],
   "source": [
    "# data_idtor = train_idtor + test_idtor\n",
    "# apply random train/test mask to the matrix, and ensure no one row or column is fully masked\n",
    "valid_condition = False\n",
    "trial = 0\n",
    "while not valid_condition:\n",
    "    train_idtor = torch.bernoulli(data_idtor * 0.8).int()\n",
    "    test_idtor = data_idtor - train_idtor\n",
    "    valid_condition = (train_idtor.sum(axis=1) != 0).all() and (train_idtor.sum(axis=0) != 0).all()\n",
    "    print(f\"trial {trial} valid condition: {valid_condition}\")\n",
    "    trial += 1\n",
    "\n",
    "# fit z\n",
    "B = 50000\n",
    "optimized_zs = []\n",
    "thetas_nuisance = torch.randn(150, n_test_takers, device=device)\n",
    "for i in tqdm(range(0, n_items, B)):\n",
    "    data_batch = data_with0[:, i:i+B]\n",
    "    train_idtor_batch = train_idtor[:, i:i+B]\n",
    "    current_B = data_batch.shape[1]\n",
    "    z_i = torch.randn(current_B, requires_grad=True, device=device)\n",
    "    optim_z_i = LBFGS([z_i], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "    def closure_z_i():\n",
    "        optim_z_i.zero_grad()\n",
    "        probs = torch.sigmoid(thetas_nuisance[:, :, None] + z_i[None, None, :])\n",
    "        loss = -(Bernoulli(probs=probs).log_prob(data_batch)*train_idtor_batch).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    z_i_optimized = trainer([z_i], optim_z_i, closure_z_i)[0].detach()\n",
    "    optimized_zs.append(z_i_optimized)\n",
    "zs = torch.cat(optimized_zs)\n",
    "\n",
    "# fit theta\n",
    "thetas = torch.randn(n_test_takers, requires_grad=True, device=device)\n",
    "optim_theta = LBFGS([thetas], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "def closure_theta():\n",
    "    optim_theta.zero_grad()\n",
    "    probs = torch.sigmoid(thetas[:, None] + zs[None, :])\n",
    "    loss = -(Bernoulli(probs=probs).log_prob(data_with0)*train_idtor).mean()\n",
    "    loss.backward()\n",
    "    return loss\n",
    "thetas = trainer([thetas], optim_theta, closure_theta)[0]\n",
    "\n",
    "# calculate metrics\n",
    "probs = torch.sigmoid(thetas[:, None] + zs[None, :])\n",
    "\n",
    "train_auc, test_auc = compute_auc(probs, data_with0, train_idtor, test_idtor)\n",
    "metric_results[\"combined_data\"][\"train_auc\"] = train_auc.item()\n",
    "metric_results[\"combined_data\"][\"test_auc\"] = test_auc.item()\n",
    "\n",
    "train_cttcorr, test_cttcorr = compute_cttcorr(probs, data_with0, train_idtor, test_idtor)\n",
    "metric_results[\"combined_data\"][\"train_cttcorr\"] = train_cttcorr.item()\n",
    "metric_results[\"combined_data\"][\"test_cttcorr\"] = test_cttcorr.item()\n",
    "\n",
    "del optim_theta, thetas, z_i, thetas_nuisance, optim_z_i\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rasch\n",
    "\n",
    "fit one theta for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lsat_qa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.688523530960083\n",
      "test auc: 0.6194833517074585\n",
      "train cttcorr: 0.9999999954797291\n",
      "test cttcorr: 0.5906119125422994\n",
      "\n",
      "truthful_qa\n",
      "train auc: 0.7754234075546265\n",
      "test auc: 0.752168595790863\n",
      "train cttcorr: 0.9999999890694462\n",
      "test cttcorr: 0.9706165826374094\n",
      "\n",
      "synthetic_reasoning\n",
      "train auc: 0.8787771463394165\n",
      "test auc: 0.8685898780822754\n",
      "train cttcorr: 0.9999999995909886\n",
      "test cttcorr: 0.9944507503020064\n",
      "\n",
      "babi_qa\n",
      "train auc: 0.8385953307151794\n",
      "test auc: 0.825733482837677\n",
      "train cttcorr: 0.9999999976074504\n",
      "test cttcorr: 0.9801349393837014\n",
      "\n",
      "wikifact\n",
      "train auc: 0.8949015140533447\n",
      "test auc: 0.8836542367935181\n",
      "train cttcorr: 0.9999999986407333\n",
      "test cttcorr: 0.9955563464912967\n",
      "\n",
      "bbq\n",
      "train auc: 0.7257800102233887\n",
      "test auc: 0.6776220798492432\n",
      "train cttcorr: 0.9999999872610216\n",
      "test cttcorr: 0.9853548320237024\n",
      "\n",
      "thai_exam\n",
      "train auc: 0.857973575592041\n",
      "test auc: 0.8284746408462524\n",
      "train cttcorr: 0.9999999915025175\n",
      "test cttcorr: 0.9473795683343597\n",
      "\n",
      "dyck_language_np=3\n",
      "train auc: 0.7987954020500183\n",
      "test auc: 0.7705100774765015\n",
      "train cttcorr: 0.99999999921584\n",
      "test cttcorr: 0.9523431791191582\n",
      "\n",
      "legal_support\n",
      "train auc: 0.7143356800079346\n",
      "test auc: 0.6697757244110107\n",
      "train cttcorr: 0.9999999976040401\n",
      "test cttcorr: 0.8647175288487944\n",
      "\n",
      "civil_comments\n",
      "train auc: 0.7923104763031006\n",
      "test auc: 0.774608314037323\n",
      "train cttcorr: 0.9999999982895018\n",
      "test cttcorr: 0.9993321449878049\n",
      "\n",
      "legalbench\n",
      "train auc: 0.8490860462188721\n",
      "test auc: 0.836212158203125\n",
      "train cttcorr: 0.9999999853873718\n",
      "test cttcorr: 0.9853292991185817\n",
      "\n",
      "raft\n",
      "train auc: 0.8433337211608887\n",
      "test auc: 0.8359396457672119\n",
      "train cttcorr: 0.9999999898960499\n",
      "test cttcorr: 0.9667072922095117\n",
      "\n",
      "air_bench_2024\n",
      "train auc: 0.9189774990081787\n",
      "test auc: 0.9038318991661072\n",
      "train cttcorr: 0.9999999965323432\n",
      "test cttcorr: 0.9979504514385135\n",
      "\n",
      "math\n",
      "train auc: 0.9069100618362427\n",
      "test auc: 0.8989916443824768\n",
      "train cttcorr: 0.9999999994130362\n",
      "test cttcorr: 0.9904288659823243\n",
      "\n",
      "med_qa\n",
      "train auc: 0.8781333565711975\n",
      "test auc: 0.869013786315918\n",
      "train cttcorr: 0.9999999955530873\n",
      "test cttcorr: 0.9823410596225498\n",
      "\n",
      "gsm\n",
      "train auc: 0.9062897562980652\n",
      "test auc: 0.8985381722450256\n",
      "train cttcorr: 0.9999999995129949\n",
      "test cttcorr: 0.9927657682987716\n",
      "\n",
      "boolq\n",
      "train auc: 0.8516445159912109\n",
      "test auc: 0.833503007888794\n",
      "train cttcorr: 0.9999999996984892\n",
      "test cttcorr: 0.993096924815468\n",
      "\n",
      "mmlu\n",
      "train auc: 0.9107261896133423\n",
      "test auc: 0.8993809223175049\n",
      "train cttcorr: 0.999999994816744\n",
      "test cttcorr: 0.9973090123780943\n",
      "\n",
      "entity_matching\n",
      "train auc: 0.9005221128463745\n",
      "test auc: 0.8869590759277344\n",
      "train cttcorr: 0.9999999996850908\n",
      "test cttcorr: 0.996777295569847\n",
      "\n",
      "entity_data_imputation\n",
      "train auc: 0.9436786770820618\n",
      "test auc: 0.9344797134399414\n",
      "train cttcorr: 0.9999999995785793\n",
      "test cttcorr: 0.96432828871636\n",
      "\n",
      "commonsense\n",
      "train auc: 0.9296308755874634\n",
      "test auc: 0.9203937649726868\n",
      "train cttcorr: 0.9999999981061295\n",
      "test cttcorr: 0.9816468838401071\n",
      "\n",
      "imdb\n",
      "train auc: 0.9275050163269043\n",
      "test auc: 0.8829501271247864\n",
      "train cttcorr: 0.9999999868962981\n",
      "test cttcorr: 0.9922439784181618\n"
     ]
    }
   ],
   "source": [
    "calres_dir = \"../data/calibration_result\"\n",
    "os.makedirs(calres_dir, exist_ok=True)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{scenario}\")\n",
    "    mask = (results.columns.get_level_values(\"scenario\") == scenario)\n",
    "    data_scenario = data_with0[:, mask]\n",
    "    train_idtor_scenario = train_idtor[:, mask]\n",
    "    test_idtor_scenario = test_idtor[:, mask]\n",
    "    z_scenario = zs[mask]\n",
    "    df_z = pd.DataFrame({\"z\": z_scenario.detach().cpu().numpy()})\n",
    "    df_z.to_csv(f'{calres_dir}/z_{scenario}.csv', index=False)\n",
    "\n",
    "    thetas = torch.zeros(n_test_takers, requires_grad=True, device=device)\n",
    "    optim_theta = torch.optim.LBFGS([thetas], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "    def closure_theta():\n",
    "        optim_theta.zero_grad()\n",
    "        probs = torch.sigmoid(thetas[:, None] + z_scenario[None, :])\n",
    "        loss = -(Bernoulli(probs=probs).log_prob(data_scenario)*train_idtor_scenario).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    thetas = trainer([thetas], optim_theta, closure_theta, verbose=False)[0]\n",
    "    df_theta = pd.DataFrame({\"theta\": thetas.detach().cpu().numpy()})\n",
    "    df_theta = df_theta[df_theta[\"theta\"] != 0]\n",
    "    df_theta.to_csv(f'{calres_dir}/theta_{scenario}.csv', index=False)\n",
    "\n",
    "    probs = torch.sigmoid(thetas[:, None] + z_scenario[None, :])\n",
    "    train_auc, test_auc = compute_auc(probs, data_scenario, train_idtor_scenario, test_idtor_scenario)\n",
    "    metric_results[scenario][\"train_auc\"] = train_auc.item()\n",
    "    metric_results[scenario][\"test_auc\"] = test_auc.item()\n",
    "    \n",
    "    train_cttcorr, test_cttcorr = compute_cttcorr(probs, data_scenario, train_idtor_scenario, test_idtor_scenario)\n",
    "    metric_results[scenario][\"train_cttcorr\"] = train_cttcorr.item()\n",
    "    metric_results[scenario][\"test_cttcorr\"] = test_cttcorr.item()\n",
    "\n",
    "del zs, optim_theta, thetas\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = [\n",
    "    auc_train_0, auc_train_1_2, auc_train_1_1, \n",
    "    metric_results[\"combined_data\"][\"test_auc\"],\n",
    "    np.max(np.array([metric_results[scenario][\"test_auc\"] for scenario in scenarios]))\n",
    "]\n",
    "labels = ['Naive', 'Average score', 'Difficulty modeling', 'Simple Rasch', 'Rasch']\n",
    "\n",
    "with plt.rc_context(bundles.icml2024(usetex=True, family=\"serif\")):\n",
    "    fig, ax = plt.subplots(figsize=(10, 2.5))\n",
    "    bars = ax.bar(labels, values, color='#b37fbf')\n",
    "\n",
    "    ax.set_xlabel(r'Response Model', fontsize=15)\n",
    "    ax.set_ylabel(r'AUC on Test Set', fontsize=18)\n",
    "    ax.set_ylim(0.4, 1.0)\n",
    "    ax.set_yticks([i/5 for i in range(3, 6)])\n",
    "    plt.tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "    for bar, v in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, v + 0.01, f'{v:.2f}', \n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    plt.savefig(\"../result/test_auc_grow.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amortized Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of questions with feature:  0.9996951222419739\n"
     ]
    }
   ],
   "source": [
    "with open(f\"../data/embed_meta-llama_Llama-3.1-8B-Instruct.pkl\", \"rb\") as f:\n",
    "    df_embed = pickle.load(f)\n",
    "question_to_emb = dict(zip(df_embed[\"question\"], df_embed[\"embedding\"]))\n",
    "questions = results.columns.get_level_values(\"input.text\").tolist()\n",
    "embeds = [question_to_emb.get(q, None) for q in questions]\n",
    "embed_dim = len(next(item for item in embeds if item is not None))\n",
    "print(f\"embed_dim: {embed_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "entity_data_imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:11,  8.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [00:07<00:01, 11.99it/s, grad_norm=7.6e-7, d_parameter=0, d_loss=4.18e-9]        \n",
      " 12%|█▏        | 12/100 [00:00<00:01, 70.27it/s, grad_norm=1.79e-7, d_parameter=0, d_loss=-2.19e-10]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.9439506530761719\n",
      "test auc: 0.9180223941802979\n",
      "train cttcorr: 0.9999999993333711\n",
      "test cttcorr: 0.967654010929555\n",
      "\n",
      "commonsense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:02<00:10,  7.88it/s, grad_norm=1.34e-6, d_parameter=0, d_loss=9.14e-9]     \n",
      " 12%|█▏        | 12/100 [00:00<00:01, 84.41it/s, grad_norm=4.53e-7, d_parameter=0, d_loss=1.63e-10]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.9292876720428467\n",
      "test auc: 0.7974473237991333\n",
      "train cttcorr: 0.9999999980032216\n",
      "test cttcorr: 0.9836946543690086\n",
      "\n",
      "imdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:59<00:00,  1.67it/s, grad_norm=7.33e-6, d_parameter=1.08, d_loss=2.4e-6]  \n",
      " 11%|█         | 11/100 [00:00<00:00, 102.93it/s, grad_norm=2.55e-7, d_parameter=0, d_loss=7.82e-11]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.925557017326355\n",
      "test auc: 0.8450058102607727\n",
      "train cttcorr: 0.9999999871288912\n",
      "test cttcorr: 0.9919793604970778\n",
      "\n",
      "combined_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:47<00:00,  4.07s/it, grad_norm=0.000705, d_parameter=0.0161, d_loss=-0.00116]  \n",
      " 15%|█▌        | 15/100 [00:00<00:03, 23.44it/s, grad_norm=2.47e-7, d_parameter=0, d_loss=1.06e-10]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.7399625778198242\n",
      "test auc: 0.7375156879425049\n",
      "train cttcorr: 0.9999987607753383\n",
      "test cttcorr: 0.9958644083237587\n"
     ]
    }
   ],
   "source": [
    "all_scenarios = results.columns.get_level_values(\"scenario\").unique().tolist() + [\"combined_data\"]\n",
    "for scenario in all_scenarios:\n",
    "    print(f\"\\n{scenario}\")\n",
    "    \n",
    "    if scenario != \"combined_data\":\n",
    "        mask = (results.columns.get_level_values(\"scenario\") == scenario)\n",
    "        data_scenario = data_with0[:, mask]\n",
    "        data_idtor_scenario = data_idtor[:, mask]\n",
    "        embeds_scenario = [emb for emb, m in zip(embeds, mask) if m]\n",
    "    else:\n",
    "        data_scenario = data_with0\n",
    "        data_idtor_scenario = data_idtor\n",
    "        test_idtor_scenario = test_idtor\n",
    "        embeds_scenario = embeds\n",
    "    n_items_scenario = data_scenario.shape[1]\n",
    "    \n",
    "    has_feature = [0.0 if item is None else 1.0 for item in embeds_scenario]\n",
    "    has_feature = torch.tensor(has_feature, dtype=torch.float, device=device)\n",
    "    has_feature_train = torch.bernoulli(has_feature * 0.8).int()\n",
    "    has_feature_test = (has_feature - has_feature_train).int()\n",
    "\n",
    "    features = [[0] * embed_dim if i is None else i for i in embeds_scenario]\n",
    "    features = torch.tensor(features, dtype=torch.float, device=device)\n",
    "    train_idtor_scenario = has_feature_train[None, :].repeat(n_test_takers, 1) * data_idtor_scenario\n",
    "    test_idtor_scenario = has_feature_test[None, :].repeat(n_test_takers, 1) * data_idtor_scenario\n",
    "    \n",
    "    B = 50000\n",
    "    thetas_nuisance = torch.randn(150, n_test_takers, device=device)\n",
    "    w = torch.randn(embed_dim, requires_grad=True, device=device)\n",
    "    b = torch.randn(1, requires_grad=True, device=device)\n",
    "    z_free = torch.zeros(n_items_scenario, requires_grad=True, device=device)\n",
    "    optim_z = LBFGS([z_free, w, b], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "    \n",
    "    def closure_z():\n",
    "        idx = torch.randperm(n_items_scenario)[:B]\n",
    "        data_batch = data_scenario[:, idx]\n",
    "        train_idtor_batch = train_idtor_scenario[:, idx]\n",
    "        features_batch = features[idx]\n",
    "        has_feature_train_batch = has_feature_train[idx]\n",
    "        z_free_batch = z_free[idx]\n",
    "        \n",
    "        optim_z.zero_grad()\n",
    "        z = z_free_batch * (1 - has_feature_train_batch) + (features_batch@w + b) * has_feature_train_batch\n",
    "        probs = torch.sigmoid(thetas_nuisance[:, :, None] + z[None, None, :])\n",
    "        loss = -(Bernoulli(probs=probs).log_prob(data_batch)*train_idtor_batch).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    z_free, w, b = trainer([z_free, w, b], optim_z, closure_z)\n",
    "    z = z_free * (1 - has_feature) + (features@w + b) * has_feature\n",
    "    z = z.detach()\n",
    "\n",
    "    thetas = torch.randn(n_test_takers, requires_grad=True, device=device)\n",
    "    optim_theta = LBFGS([thetas], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "    def closure_theta():\n",
    "        optim_theta.zero_grad()\n",
    "        probs = torch.sigmoid(thetas[:, None] + z[None, :])\n",
    "        loss = -(Bernoulli(probs=probs).log_prob(data_scenario)*train_idtor_scenario).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    thetas = trainer([thetas], optim_theta, closure_theta)[0]\n",
    "\n",
    "    probs = torch.sigmoid(thetas[:, None] + z[None, :])\n",
    "    \n",
    "    train_auc, test_auc = compute_auc(probs, data_scenario, train_idtor_scenario, test_idtor_scenario)\n",
    "    metric_results[scenario][\"amortized_train_auc\"] = train_auc.item()\n",
    "    metric_results[scenario][\"amortized_test_auc\"] = test_auc.item()\n",
    "\n",
    "    train_cttcorr, test_cttcorr = compute_cttcorr(probs, data_scenario, train_idtor_scenario, test_idtor_scenario)\n",
    "    metric_results[scenario][\"amortized_train_cttcorr\"] = train_cttcorr.item()\n",
    "    metric_results[scenario][\"amortized_test_cttcorr\"] = test_cttcorr.item()\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/calibration_metric_results.json', 'w') as f:\n",
    "    json.dump(metric_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_double(\n",
    "    data1_train,\n",
    "    data1_test,\n",
    "    data2_train,\n",
    "    data2_test,\n",
    "    plot_path,\n",
    "    metric_name,\n",
    "):\n",
    "    with plt.rc_context(bundles.icml2024(usetex=True, family=\"serif\")):\n",
    "        corr_train = pearsonr(data1_train, data2_train).statistic\n",
    "        corr_test  = pearsonr(data1_test,  data2_test ).statistic\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(data1_train, data2_train, color=\"blue\", label=\"Train\")\n",
    "        plt.scatter(data1_test,  data2_test, color=\"red\",  label=\"Test\")\n",
    "        plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"black\")\n",
    "\n",
    "        plt.xlabel(r\"Amortized Calibration\", fontsize=25)\n",
    "        plt.ylabel(r\"Traditional Calibration\", fontsize=25)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "        title = (\n",
    "            rf\"{metric_name}. \"\n",
    "            rf\"$\\rho_{{train}}$ = {corr_train:.2f}, \"\n",
    "            rf\"$\\rho_{{test}}$ = {corr_test:.2f}\"\n",
    "        )\n",
    "        plt.title(title, fontsize=25)\n",
    "\n",
    "        plt.tick_params(axis=\"both\", labelsize=16)\n",
    "        plt.legend(fontsize=16)\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    \n",
    "with open(\"../result/calibration_metric_results.json\", \"r\") as f:\n",
    "    metric_results = json.load(f)\n",
    "\n",
    "train_aucs = []\n",
    "test_aucs = []\n",
    "amor_train_aucs = []\n",
    "amor_test_aucs = []\n",
    "for scenario in metric_results:\n",
    "    train_aucs.append(metric_results[scenario][\"train_auc\"])\n",
    "    test_aucs.append(metric_results[scenario][\"test_auc\"])\n",
    "    amor_train_aucs.append(metric_results[scenario][\"amortized_train_auc\"])\n",
    "    amor_test_aucs.append(metric_results[scenario][\"amortized_test_auc\"])\n",
    "plot_corr_double(amor_train_aucs, amor_test_aucs, train_aucs, test_aucs, \"../result/amor_vs_trad_auc.png\", r\"AUC-ROC\")\n",
    "\n",
    "train_cttcorrs = []\n",
    "test_cttcorrs = []\n",
    "amor_train_cttcorrs = []\n",
    "amor_test_cttcorrs = []\n",
    "for scenario in metric_results:\n",
    "    train_cttcorrs.append(metric_results[scenario][\"train_cttcorr\"])\n",
    "    test_cttcorrs.append(metric_results[scenario][\"test_cttcorr\"])\n",
    "    amor_train_cttcorrs.append(metric_results[scenario][\"amortized_train_cttcorr\"])\n",
    "    amor_test_cttcorrs.append(metric_results[scenario][\"amortized_test_cttcorr\"])\n",
    "plot_corr_double(amor_train_cttcorrs, amor_test_cttcorrs, train_cttcorrs, test_cttcorrs, \"../result/amor_vs_trad_cttcorr.png\", r\"$\\theta$ Corr Avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amortize Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
